{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/__init__.py:249\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(textwrap\u001b[39m.\u001b[39mdedent(\u001b[39m'''\u001b[39m\n\u001b[1;32m    236\u001b[0m \u001b[39m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[1;32m    237\u001b[0m \u001b[39m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39m                or by running Python from a different directory.\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39m            \u001b[39m\u001b[39m'''\u001b[39m)\u001b[39m.\u001b[39mstrip()) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    247\u001b[0m     \u001b[39mraise\u001b[39;00m  \u001b[39m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m(_C):\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m name[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m name\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39mBase\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    251\u001b[0m         __all__\u001b[39m.\u001b[39mappend(name)\n",
      "\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "#only pick the 9th column\n",
    "df = pd.read_csv('test.csv', usecols=[9])\n",
    "# drop NaN values\n",
    "df = df.dropna()\n",
    "df\n",
    "\n",
    "\n",
    "df\n",
    "df.plot()\n",
    "df.head()\n",
    "#type of data\n",
    "y = df.values.astype(float)\n",
    "y\n",
    "train_size = int(len(df)*0.93) # 93% of data for training, 7% for testing\n",
    "train_data = y[:train_size] # all data except the train_size\n",
    "val_data = y[train_size:] # the last 7% of the data\n",
    "train_data\n",
    "# define the block size, \n",
    "block_size = 128 # 128 days of data to predict the next day\n",
    "batch_size = 32 # number of samples in a batch for training the model\n",
    "train_data[:block_size]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# define the scaler and fit it to the training data\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler.fit(train_data.reshape(-1, 1))\n",
    "\n",
    "def get_batch(split):\n",
    "    # Select the appropriate dataset based on the split\n",
    "    data = train_data if split == 'train' else val_data\n",
    "\n",
    "    # Generate a random index for each batch\n",
    "    ix = np.random.randint(0, len(data) - block_size - 1, batch_size)\n",
    "\n",
    "    # Extract the blocks of data for each batch\n",
    "    x = [data[i:i+block_size] for i in ix]\n",
    "    y = [data[i+1:i+block_size+1] for i in ix]\n",
    "\n",
    "\n",
    "\n",
    "    # Normalize each block of x and y using the scaler fitted to the training data\n",
    "    x_norm = [scaler.transform(block.reshape(-1, 1)).reshape(-1) for block in x]\n",
    "    y_norm = [scaler.transform(block.reshape(-1, 1)).reshape(-1) for block in y]\n",
    "\n",
    "    # Convert x and y to tensors\n",
    "    # Convert x and y to tensors\n",
    "    x = torch.tensor(x_norm, dtype=torch.float32)\n",
    "    y = torch.tensor(y_norm, dtype=torch.float32)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "x, y = get_batch('train')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('inputs')\n",
    "print(x.shape)\n",
    "print(x)\n",
    "print('targets')\n",
    "print(y.shape)\n",
    "print(y)\n",
    "\n",
    "def positionalEncoding(x):\n",
    "    seq_len, n_features = x.shape\n",
    "    pos = torch.arange(seq_len, dtype=torch.float).reshape(-1, 1)\n",
    "    i = torch.arange(n_features, dtype=torch.float).reshape(1, -1)\n",
    "    angle = pos / (10000 ** (2 * (i // 2) / n_features))\n",
    "    encoding = torch.zeros((seq_len, n_features))\n",
    "    encoding[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "    encoding[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "    return x + encoding\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # Define the query, key, and value linear projections\n",
    "        self.query_proj = nn.Linear(hidden_size, hidden_size)\n",
    "        self.key_proj = nn.Linear(hidden_size, hidden_size)\n",
    "        self.value_proj = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        # Define the output linear projection\n",
    "        self.output_proj = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size, seq_len, hidden_size = inputs.size()\n",
    "\n",
    "        # Project the inputs to get the queries, keys, and values\n",
    "        queries = self.query_proj(inputs)\n",
    "        keys = self.key_proj(inputs)\n",
    "        values = self.value_proj(inputs)\n",
    "\n",
    "        # Reshape the queries, keys, and values to have num_heads\n",
    "        queries = queries.view(batch_size, seq_len, self.num_heads, hidden_size // self.num_heads).transpose(1, 2)\n",
    "        keys = keys.view(batch_size, seq_len, self.num_heads, hidden_size // self.num_heads).transpose(1, 2)\n",
    "        values = values.view(batch_size, seq_len, self.num_heads, hidden_size // self.num_heads).transpose(1, 2)\n",
    "\n",
    "        # Compute the self-attention scores\n",
    "        scores = torch.matmul(queries, keys.transpose(-2, -1)) / math.sqrt(hidden_size // self.num_heads)\n",
    "\n",
    "        # Apply a mask to the scores (if provided)\n",
    "        mask = torch.tril(torch.ones((seq_len, seq_len), dtype=torch.uint8)).to(inputs.device)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # Apply the softmax function to get the attention weights\n",
    "        weights = torch.softmax(scores, dim=-1)\n",
    "\n",
    "        # Apply the attention weights to the values\n",
    "        attn_output = torch.matmul(weights, values)\n",
    "\n",
    "        # Reshape and concatenate the attention output\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, hidden_size)\n",
    "\n",
    "        # Project the attention output to get the final output\n",
    "        output = self.output_proj(attn_output)\n",
    "\n",
    "        return output, weights\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads, dropout_prob):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = SelfAttention(hidden_size, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size * 4)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_size * 4, hidden_size)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Multi-Head Attention\n",
    "        attn_output, _ = self.attention(inputs)\n",
    "\n",
    "        # Add and Norm\n",
    "        x = self.norm1(inputs + self.dropout1(attn_output))\n",
    "\n",
    "        # Feed Forward\n",
    "        ffn_output = self.fc(x)\n",
    "        ffn_output = nn.functional.gelu(ffn_output)\n",
    "        ffn_output = self.fc2(ffn_output)\n",
    "\n",
    "        # Add and Norm\n",
    "        output = self.norm2(x + self.dropout2(ffn_output))\n",
    "\n",
    "        return output\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_heads, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Create a stack of transformer blocks\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(hidden_size, num_heads, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Define the input and output linear projections\n",
    "        self.input_proj = nn.Linear(input_size, hidden_size)\n",
    "        self.output_proj = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Project the inputs to the hidden size\n",
    "        inputs = self.input_proj(inputs)\n",
    "\n",
    "        # Apply the transformer blocks\n",
    "        for i in range(self.num_layers):\n",
    "            inputs = self.transformer_blocks[i](inputs)\n",
    "\n",
    "        # Project the outputs to the input size\n",
    "        outputs = self.output_proj(inputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads, feedforward_size, dropout):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.self_attention = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout)\n",
    "        self.enc_dec_attention = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout)\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(hidden_size, feedforward_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(feedforward_size, hidden_size),\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(hidden_size)\n",
    "        self.norm3 = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, target, memory, target_mask=None, memory_mask=None):\n",
    "        # Self-attention layer\n",
    "        out, _ = self.self_attention(target, target, target, attn_mask=target_mask)\n",
    "        target = self.norm1(target + self.dropout(out))\n",
    "\n",
    "        # Encoder-decoder attention layer\n",
    "        out, _ = self.enc_dec_attention(target, memory, memory, attn_mask=memory_mask)\n",
    "        target = self.norm2(target + self.dropout(out))\n",
    "\n",
    "        # Feedforward neural network layer\n",
    "        out = self.feedforward(target)\n",
    "        target = self.norm3(target + self.dropout(out))\n",
    "\n",
    "        return target\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_heads, feedforward_size, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.feedforward_size = feedforward_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Create a stack of decoder blocks\n",
    "        self.decoder_blocks = nn.ModuleList([\n",
    "            DecoderBlock(hidden_size, num_heads, feedforward_size, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Define the input and output linear projections\n",
    "        self.input_proj = nn.Linear(input_size, hidden_size)\n",
    "        self.output_proj = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, inputs, memory, input_mask=None, memory_mask=None):\n",
    "        # Project the inputs to the hidden size\n",
    "        inputs = self.input_proj(inputs)\n",
    "\n",
    "        # Apply the decoder blocks\n",
    "        for i in range(self.num_layers):\n",
    "            inputs = self.decoder_blocks[i](inputs, memory, input_mask, memory_mask)\n",
    "\n",
    "        # Project the outputs to the input size\n",
    "        outputs = self.output_proj(inputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_heads, feedforward_size, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(input_size, hidden_size, num_layers, num_heads, dropout=dropout)\n",
    "        self.decoder = Decoder(input_size, hidden_size, num_layers, num_heads, feedforward_size, dropout)\n",
    "        self.output_proj = nn.Linear(hidden_size, 1)  # changed output size to hidden_size\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Encode the inputs\n",
    "        enc_outputs = self.encoder(inputs)\n",
    "        # Decode the inputs\n",
    "        dec_outputs = self.decoder(inputs, enc_outputs)\n",
    "        # Project the outputs to a single value\n",
    "        outputs = self.output_proj(dec_outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49e5114a44c7dce7391737614524762807e29f411c2ff3aa148b7ad90e832318"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
